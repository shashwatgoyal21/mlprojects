{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29cb4ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/09 16:11:34 INFO mlflow.tracking.fluent: Experiment with name 'Text Message Angel1' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "#%pip install mlflow\n",
    "\n",
    "from mlflow import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"Text Message Angel1\")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Determine if this is an acceptable response to a friend through SMS. \"\n",
    "            \"If the response contains humorless sarcasm, a passive aggressive tone, or could potentially \"\n",
    "            \"damage my relationship with them, please respond with 'You might want to read that again before \"\n",
    "            \"pressing send.', otherwise respond with 'Good to Go!'. If the response classifies as inappropriate, \"\n",
    "            \"please suggest a corrected version following the classification that will help to keep my \"\n",
    "            \"relationship with this person intact, yet still maintains a fun and somewhat snarky tone: {text}\"\n",
    "        ),\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "289dc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openai\n",
    "#%pip install os\n",
    "\n",
    "import os\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import ColSpec, ParamSchema, ParamSpec, Schema\n",
    "\n",
    "# Run a quick validation that we have an entry for the OPEN_API_KEY within environment variables\n",
    "assert \"OPENAI_API_KEY\" in os.environ, \"OPENAI_API_KEY environment variable must be set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0946d585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (1.77.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tenacity in c:\\users\\tanya\\onedrive\\desktop\\personal\\pdp\\mlops3\\mlopsenv\\lib\\site-packages (9.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openai tiktoken\n",
    "\n",
    "%pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1073d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tiktoken\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.openai.log_model(\n",
    "        model=\"gpt-4\",\n",
    "        task=openai.chat.completions,\n",
    "        artifact_path=\"model\",\n",
    "        messages=messages,\n",
    "        signature=ModelSignature(\n",
    "            inputs=Schema([ColSpec(type=\"string\", name=None)]),\n",
    "            outputs=Schema([ColSpec(type=\"string\", name=None)]),\n",
    "            params=ParamSchema(\n",
    "                [\n",
    "                    ParamSpec(name=\"max_tokens\", default=16, dtype=\"long\"),\n",
    "                    ParamSpec(name=\"temperature\", default=0, dtype=\"float\"),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c300c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.pyfunc.load_model(model_info.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e9b5e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><strong>You might want to read that again before pressing send.\n",
       "\n",
       "Suggested response: \"Wow, dinner last night was certainly unique! Who knew your secret ingredient would be so... unexpected? You're always full of surprises!\"</strong></p><br><p><strong>You might want to read that again before pressing send.\n",
       "\n",
       "Suggested correction: \"I'm not sure I can make the movies on Thursday, but how about we find a time that works for both of us?\"</strong></p><br><p><strong>Good to Go!</strong></p><br><p><strong>Good to Go!</strong></p><br><p><strong>You might want to read that again before pressing send.\n",
       "\n",
       "Suggested correction: You know what part I love most when you sing? The encore. It means I get to hear you again!</strong></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_data = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [\n",
    "            \"Wow, what an interesting dinner last night! I had no idea that you could use canned \"\n",
    "            \"cat food to make a meatloaf.\",\n",
    "            \"I'd rather book a 14th century surgical operation than go to the movies with you on Thursday.\",\n",
    "            \"Can't wait for the roadtrip this weekend! Love the playlist mixes that you choose!\",\n",
    "            \"Thanks for helping out with the move this weekend. I really appreciate it.\",\n",
    "            \"You know what part I love most when you sing? The end. It means its over.\",\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "chat_completions_response = model.predict(\n",
    "    validation_data, params={\"max_tokens\": 50, \"temperature\": 0.2}\n",
    ")\n",
    "\n",
    "formatted_output = \"<br>\".join(\n",
    "    [f\"<p><strong>{line.strip()}</strong></p>\" for line in chat_completions_response]\n",
    ")\n",
    "display(HTML(formatted_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51101a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/tanya/OneDrive/Desktop/personal/pdp/GenAI/krish_naik/Langchain/mlflow%20with%20llm/mlruns/789764049556921323', creation_time=1746787294779, experiment_id='789764049556921323', last_update_time=1746787294779, lifecycle_stage='active', name='Text Message Angel1', tags={}>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Text Message Angel1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "210af013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Good to Go!',\n",
       " \"'Good to Go!'\",\n",
       " 'You might want to read that again before pressing send.\\n\\nSuggested response: \"',\n",
       " 'You might want to read that again before pressing send.\\n\\nSuggested response: \"']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/69b470f41df145ccbc946f14dfcb8abd/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [\n",
    "            \"I am not sure if I should ask but how was the dinner\",\n",
    "            \"Can you give me more details about your ex-gf\",\n",
    "            \"This is not a wise thing to do at all\",\n",
    "            \"Logout of my computer immediately\"\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e752fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlopsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
